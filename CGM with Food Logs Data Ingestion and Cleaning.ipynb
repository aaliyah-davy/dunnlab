{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8ecbb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "import scipy.fft\n",
    "from scipy import signal\n",
    "from scipy.stats import entropy\n",
    "from scipy.integrate import trapz\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# _______New CGM Class + Merge Function_______\n",
    "# comes with ALL values merged on one dataframe\n",
    "# Updated 11-25-24\n",
    "\n",
    "class CGM_Wide_DF:\n",
    "    def __init__(self, n, path=\"physio_wfood/\"):\n",
    "        self.n = n\n",
    "        self.path = path\n",
    "        self.df = -1\n",
    "        self.dex = -1\n",
    "        self.acc = -1\n",
    "        self.tem = -1\n",
    "        self.bvp = -1\n",
    "        self.eda = -1\n",
    "        self.hr = -1\n",
    "        self.ibi = -1\n",
    "        self.flg = -1\n",
    "        self.meal_df = -1\n",
    "        self.meal_dt = -1\n",
    "        self.markers = -1\n",
    "        self.dex_windows = -1\n",
    "        self.areas = -1\n",
    "        self.intp_2hr_areas = -1\n",
    "        self.intp_5hr_areas = -1\n",
    "        self.raw_gluc_df = -1\n",
    "        self.intp_2hrs_df = -1\n",
    "        self.intp_5hrs_df = -1\n",
    "        self.parse_file()\n",
    "        self.get_meal_df()\n",
    "        self.get_bmarker_dicts()\n",
    "        self.assemble()\n",
    "    \n",
    "    def parse_file(self):\n",
    "        \"\"\"\n",
    "        - Parses all dataframes in Subject's folder.\n",
    "        - Updates the respective Class attribute for easy access after run \n",
    "        at user's discretion.\n",
    "        - Ran at class instantiation.\n",
    "        \"\"\"\n",
    "        # Gets all csv files in Subject's folder --> combines into a dictionary\n",
    "        pn = '0{n}'.format(n=self.n).zfill(3)\n",
    "        path = self.path+pn+'/'\n",
    "        folder = [o for o in os.listdir(path) if o[:1].isalpha()]\n",
    "        dfs = [pd.read_csv(path+f) for f in folder]\n",
    "        self.df = dict(zip(folder, dfs))\n",
    "\n",
    "        # Formats Dexcom dataframe (keeps only datetime and glucose columns)\n",
    "        dex = self.df['Dexcom_{n}.csv'.format(n=pn)].copy()\n",
    "        # Adjusts dex dataframe\n",
    "        mask = [col for col in dex.columns if len(dex[dex[col].notna()])<5] + \\\n",
    "                ['Event Subtype', 'Source Device ID', 'Index', \\\n",
    "                 'Event Type', 'Transmitter Time (Long Integer)',]\n",
    "        dex = dex.drop(columns=mask)\n",
    "        dex = dex[dex['Timestamp (YYYY-MM-DDThh:mm:ss)'].notna()]\n",
    "        self.dex = dex.rename(columns={'Timestamp (YYYY-MM-DDThh:mm:ss)': 'datetime'})\n",
    "        \n",
    "        def fmt_df(name):\n",
    "            # support function for Class 'parse_file' method\n",
    "            temp = self.df['{name}_{n}.csv'.format(name=name,n=pn)].copy()\n",
    "            cols = temp.columns.tolist()[1:]\n",
    "            for col in cols:\n",
    "                temp = temp.rename(columns={col:col.strip()})\n",
    "            temp = self.to_dt(temp)\n",
    "            return temp\n",
    "        \n",
    "        # Retrieves Tri-Axial Accelerometry dataframe\n",
    "        self.acc = fmt_df('ACC')\n",
    "\n",
    "        # Retrieves Skin Temperature dataframe\n",
    "        self.tem = fmt_df('TEMP')\n",
    "\n",
    "        # Retrieves Blood Volume Pulse dataframe\n",
    "        self.bvp = fmt_df('BVP')\n",
    "\n",
    "        # Retrieves Electrodermal Activity dataframe\n",
    "        self.eda = fmt_df('EDA')\n",
    "\n",
    "        # Formats Heart Rate dataframe\n",
    "        def is_iso_format(dt):\n",
    "            \"\"\"\n",
    "            Checks datetime format of a series.\n",
    "            - input: pandas Series object\n",
    "            - returns: boolean\n",
    "            \"\"\"\n",
    "            try:\n",
    "                pd.to_datetime(dt, format='%Y-%m-%d %H:%M:%S')\n",
    "                return True\n",
    "            except ValueError:\n",
    "                return False\n",
    "        \n",
    "        self.hr = fmt_df('HR')\n",
    "        # Formats hr['datetime']: change from 02/13/20 --> 2020-02-13 to match standard datetime\n",
    "        if not is_iso_format:\n",
    "            self.hr['datetime'] = [str(pd.to_datetime(h, format = \"%m/%d/%y %H:%M:%S.%f\")) for h in self.hr['datetime']]\n",
    "\n",
    "        # Formats InterBeat Interval dataframe\n",
    "        self.ibi = fmt_df('IBI')\n",
    "        \n",
    "        # Formats Food Log dataframe\n",
    "        self.flg = self.df['Food_Log_{n}.csv'.format(n=pn)].copy()\n",
    "        self.fmt_times()\n",
    "        self.align_dt()\n",
    "    \n",
    "    def to_dt(self, df):\n",
    "        \"\"\"\n",
    "        Coverts datetime column to pd.datetime object for easier parsing/manipulation.\n",
    "        - input: pandas dataframe\n",
    "        - returns: updated dataframe with pd.dataetime 'datetime column'\n",
    "        \"\"\"\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "        df = df.sort_values(by=['datetime'])\n",
    "        return df\n",
    "    \n",
    "    # Corrects Subject 12 Data Error: 'Not a Time' Error due to NaN value\n",
    "    def fmt_times(self):\n",
    "        \"\"\"\n",
    "        - Finds and fills any missing 'time' or 'time_of_day' values.\n",
    "        - Renames 'time_begin' column to 'datetime' for ease of parsing.\n",
    "        - Updates the Food Log's Class attribute.\n",
    "        \"\"\"\n",
    "        temp = self.flg.copy()\n",
    "        mask = temp.time_begin.isna()\n",
    "        time = ['time' if 'time' in temp.columns.tolist() else 'time_of_day'][0]\n",
    "        temp.loc[mask, 'time_begin'] = temp['date'] + ' ' + temp[time]\n",
    "        temp = temp.rename(columns={'time_begin': 'datetime'})\n",
    "        self.flg = temp\n",
    "    \n",
    "    # Corrects Subject 7 Data Error: (Wrong Date)\n",
    "    def align_dt(self):\n",
    "        \"\"\"\n",
    "        - Aligns Food Log datetime to Dexcom datetime, if discrepancies exist.\n",
    "        Changes both dataframe's 'datetime' column to pd.datetime objects.\n",
    "        - Updates Food Log's and Dexcom's Class attribute.\n",
    "        \"\"\"\n",
    "        # 'cond' bool checks for food log datetime descrepencies compared to Dexcom\n",
    "        dex_date = self.dex['datetime'].iloc[0][:7]\n",
    "        temp = self.flg.copy()\n",
    "        cond = temp.datetime.str.contains(dex_date).any()\n",
    "\n",
    "        # Corrects for discrepancies in food log datetime; aligned food log datetime to Dexcom datetime\n",
    "        if not cond:\n",
    "            temp['datetime'] = pd.to_datetime(temp['datetime'])\n",
    "            mask = dex['datetime'][:len(temp['datetime'])].reset_index(drop=True)\n",
    "            mask = pd.to_datetime(mask)\n",
    "            diff = mask - temp['datetime']\n",
    "            temp['datetime'] = temp['datetime'] + pd.DateOffset(days = diff[0].round('d').days)\n",
    "            temp['datetime'] = temp.datetime.dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        self.flg = self.to_dt(temp)\n",
    "        self.dex = self.to_dt(self.dex)\n",
    "\n",
    "    def to_delta(self, df):\n",
    "        \"\"\"\n",
    "        Converts 'datetime' column to day and hour columns.\n",
    "        - input: pandas dataframe.\n",
    "        - returns: updated pandas dataframe.\n",
    "        \"\"\"\n",
    "        # Converts 'datetime' to timedelta object in seconds\n",
    "        df = df.copy()\n",
    "        df['timedelta'] = df['datetime'] - df['datetime'].iloc[0]\n",
    "        df['day'] = df['timedelta'].dt.days + 1\n",
    "        # timedelta objects don't have an 'min' property --> convert seconds to min\n",
    "        df['min'] = df['timedelta'].dt.seconds // 60\n",
    "        df = df.drop(columns=['datetime','timedelta'])\n",
    "        df = df[['subject_no','day','min'] + df.columns[1:-2].tolist()]\n",
    "        return df\n",
    "    \n",
    "    def get_meal_df(self):\n",
    "        \"\"\"\n",
    "        - Combined all meal entries within 1hr of each other in order for it \n",
    "        to  be easier to calculate post-prandial Glucose Area Under the Curve.\n",
    "        - Updates the Food Log's Class attribute.\n",
    "        - Ran at class instantiation.\n",
    "        \"\"\"\n",
    "        log = self.flg.copy().fillna(0)\n",
    "        log = log[['datetime','calorie','total_carb','dietary_fiber','sugar','protein','total_fat']]\n",
    "        tol = pd.Timedelta('60 minutes')\n",
    "        mask = log['datetime'] - log['datetime'].shift(1) <= tol\n",
    "        mask = log.groupby(~mask).ngroup().cumsum() - 1\n",
    "        df = log.groupby(mask).agg('sum', numeric_only=True).reset_index(drop=True)\n",
    "        df['datetime'] = log.groupby(mask)['datetime'].first().reset_index(drop=True)\n",
    "        self.meal_df = df[['datetime'] + df.columns.tolist()[:-1]]\n",
    "        self.meal_dt = self.meal_df.datetime.copy()\n",
    "    \n",
    "    def roll_window(self, df, hrs=[False,'']):\n",
    "        \"\"\"\n",
    "        Gets rolling windows based on Food Log datetime\n",
    "        - input: pandas dataframe\n",
    "        - returns: list of pandas dataframes between Food Log datetimes\n",
    "        \"\"\"\n",
    "        meal_dt = self.meal_dt.copy()\n",
    "        if hrs[0]:\n",
    "            hr = pd.Timedelta(str(hrs[1]*60)+' minutes')\n",
    "            windows = [df[((df.datetime >= meal_dt[i]) & (df.datetime < meal_dt[i]+hr))]\\\n",
    "                       for i in range(len(meal_dt)-1)]\n",
    "        else:\n",
    "            windows = [df[((df.datetime >= meal_dt[i]) & (df.datetime < meal_dt[i+1]))]\\\n",
    "                       for i in range(len(meal_dt)-1)]\n",
    "        first = [df[df.datetime <= meal_dt.iloc[0]]]\n",
    "        last = [df[df.datetime >= meal_dt.iloc[-1]]]\n",
    "        windows = first + windows + last\n",
    "        windows = [w.reset_index(drop=True) for w in windows]\n",
    "        return windows\n",
    "\n",
    "    # ACC features\n",
    "    def acc_feats(self, window):\n",
    "        \"\"\"\n",
    "        Generates features from Tri-Accelerometry dataframe.\n",
    "        - input: list of pandas dataframes\n",
    "        - returns: dictionary of generate features.\n",
    "        \"\"\"\n",
    "        acc = {}\n",
    "        \n",
    "        # Zero-Crossing Rate\n",
    "        def zero_cross(ray):\n",
    "            return np.sum(np.abs(np.diff(np.sign(ray)))) / (2 * len(ray) - 2)\n",
    "\n",
    "        # Gets the Zero-Crassing Rate of each axis and sums them\n",
    "        acc_zcross_rate = np.sum([zero_cross(window[col]) \\\n",
    "                                    for col in window.columns.tolist()[1:]])\n",
    "        acc['acc_zcross_rate'] = round(acc_zcross_rate*100,2)\n",
    "\n",
    "        # Magnitude\n",
    "        magnitude = np.sqrt(window['acc_x']**2 + window['acc_y']**2 + \\\n",
    "                            window['acc_z']**2)\n",
    "\n",
    "        # Root Mean Square\n",
    "        rms = np.sqrt((magnitude**2).mean())\n",
    "        acc['acc_rms'] = round(rms,2)\n",
    "\n",
    "        # Peak Counts for peaks above the magnitude standard deviation\n",
    "        peaks = len(find_peaks(magnitude, prominence=magnitude.std().round())[0])\n",
    "        acc['acc_peaks'] = peaks\n",
    "\n",
    "        # Compute the Fourier Transform\n",
    "        fourier = scipy.fft.fft(pd.DataFrame(magnitude))\n",
    "        # Magnitude Spectrum\n",
    "        mag_spec = np.abs(fourier)\n",
    "        acc['acc_mag_spec_min'] = round(mag_spec.min(),2)\n",
    "        acc['acc_mag_spec_max'] = round(mag_spec.max(),2)\n",
    "        acc['acc_mag_spec_stdev'] = round(mag_spec.std(),2)\n",
    "\n",
    "        # Spectral Entropy on magnitude\n",
    "        freq, psd = signal.welch(magnitude, fs=100) # power spectral density (PSD)\n",
    "        psd_norm = psd / np.sum(psd)\n",
    "        spec_entropy = entropy(psd_norm, base=2)\n",
    "        acc['acc_spec_entropy'] = round(spec_entropy,2)\n",
    "\n",
    "        return acc\n",
    "\n",
    "    def get_bmdata(self, marker_df, acc=False):\n",
    "        \"\"\"\n",
    "        Generates quick statistics (mean, min, max, stdev) for each window \n",
    "        of marker dataframes. If input is Tri-Axial Accelerometry, it will run the 'acc_feats' function\n",
    "        - input: pandas dataframe of marker\n",
    "        - returns: list of dictionaries with quick stats by window\n",
    "        \"\"\"\n",
    "        windows = self.roll_window(marker_df)\n",
    "\n",
    "        bm_data = []\n",
    "        if not acc:\n",
    "            for i in range(len(windows)):\n",
    "                ret = {}\n",
    "                col = windows[i].columns.tolist()[-1]\n",
    "                if len(windows[i]) != 0:\n",
    "                    ret[col+'_curr'] = round(windows[i][col].values[-1],2)\n",
    "                else: \n",
    "                    ret[col+'_curr'] = np.nan\n",
    "                ret[col+'_min'] = round(windows[i][col].min(),2)\n",
    "                ret[col+'_max'] = round(windows[i][col].max(),2)\n",
    "                ret[col+'_mean'] = round(windows[i][col].mean(),2)\n",
    "                ret[col+'_stdev'] = round(windows[i][col].std(),2)\n",
    "                bm_data+=[ret]\n",
    "        else:\n",
    "            for i in range(len(windows)):\n",
    "                if len(windows[i]) != 0:\n",
    "                    bm_data+=[self.acc_feats(windows[i])]\n",
    "                else:\n",
    "                    temp = {}\n",
    "                    keys = ['acc_zcross_rate','acc_rms','acc_peaks',\\\n",
    "                             'acc_mag_spec_min','acc_mag_spec_max',\\\n",
    "                             'acc_mag_spec_stdev','acc_spec_entropy']\n",
    "                    for key in keys:\n",
    "                        temp[key] = np.nan\n",
    "                    bm_data+=[temp]\n",
    "\n",
    "        return bm_data, windows\n",
    "\n",
    "    def get_bmarker_dicts(self):\n",
    "        \"\"\"\n",
    "        - Generates quick stats for each biomarker.\n",
    "        - Updates 'markers' and 'areas' Class attribute.\n",
    "        \"\"\"\n",
    "        # pre-prandial Glucose values\n",
    "        dex_df = self.dex.copy()\n",
    "        dex, self.dex_windows = self.get_bmdata(dex_df)\n",
    "        \n",
    "        # if first dexcom window is empty (no glucose values prior to meal)\n",
    "        # start log at the next meal in order have get pre-prandial glucose\n",
    "        # for each meal entry in final df\n",
    "        if self.dex_windows[0].empty:\n",
    "            self.dex_windows = self.dex_windows[1:]\n",
    "            self.meal_df = self.meal_df[1:].reset_index(drop=True)\n",
    "            \n",
    "        if self.dex_windows[-1].empty:\n",
    "            self.dex_windows = self.dex_windows[:-1]\n",
    "            idx = self.meal_df.index.to_list()[-1]\n",
    "            self.meal_df = self.meal_df.drop(index=idx).reset_index(drop=True)\n",
    "            \n",
    "        self.meal_dt = self.meal_df.datetime.copy()\n",
    "\n",
    "        # post-prandial Glucose AUC\n",
    "        self.areas = [{'ppg_auc':np.trapz(w['Glucose Value (mg/dL)'], w.index.to_series())}\\\n",
    "                 for w in self.dex_windows][1:]\n",
    "        \n",
    "        def get_intp_areas(hrs):\n",
    "            # reads and labels glucose values backwards\n",
    "            intp_wnd = self.roll_window(self.dex, [True,hrs])\n",
    "            wnd = [w['Glucose Value (mg/dL)'] for w in intp_wnd]\n",
    "            # post-prandial Glucose AUC\n",
    "            intp_areas = [{'ppg_auc':np.trapz(w, w.index.to_series())}\\\n",
    "                     for w in wnd][1:]\n",
    "            return intp_areas\n",
    "        \n",
    "        self.intp_2hr_areas = get_intp_areas(2)\n",
    "        self.intp_5hr_areas = get_intp_areas(5)\n",
    "        \n",
    "        # Food Log to dictionary for ease of parsing\n",
    "        flg_dict = self.meal_df.round(2).to_dict('index')\n",
    "        \n",
    "        # ACC\n",
    "        acc_df = self.acc.copy()\n",
    "        acc = self.get_bmdata(acc_df, acc=True)[0]\n",
    "\n",
    "        # TEMP\n",
    "        temp_df = self.tem.copy()\n",
    "        temp = self.get_bmdata(temp_df)[0]\n",
    "\n",
    "        # EDA\n",
    "        eda_df = self.eda.copy()\n",
    "        eda = self.get_bmdata(eda_df)[0]\n",
    "\n",
    "        # HR\n",
    "        hr_df = self.hr.copy()\n",
    "        hr = self.get_bmdata(hr_df)[0]\n",
    "\n",
    "        # IBI\n",
    "        ibi_df = self.ibi.copy()\n",
    "        ibi = self.get_bmdata(ibi_df)[0]\n",
    "\n",
    "        self.markers = [flg_dict, acc, temp, eda, hr, ibi, dex]\n",
    "\n",
    "    def interpolate(self, ray, hrs):\n",
    "        \"\"\"\n",
    "        Interpolates (via scipy) input array based on input hour to get\n",
    "        consistent size glucose values for each window.\n",
    "        - input: \n",
    "            --> 'ray' - numpy array\n",
    "            --> 'hrs' - integer\n",
    "        - returns: interpolated numpy array\n",
    "        \"\"\"\n",
    "        x = np.array(ray)\n",
    "        i = hrs*12\n",
    "        z = i / len(x)\n",
    "\n",
    "        intp = np.round(zoom(x,z), 2)\n",
    "        return intp\n",
    "\n",
    "    def get_gluc_dict(self):\n",
    "        \"\"\"\n",
    "        Generates a list of dictionaries by window with labeled timeframe \n",
    "        keys identifying how many minutes prior to meal the glucose value\n",
    "        was taken.\n",
    "            return: \n",
    "                --> raw_gluc_dict - dictionaries of variable length with \n",
    "                                    raw glucose values (not interpolated)\n",
    "                --> intp_2hrs_dict - dictionaries of consistent length with \n",
    "                                     interpolated glucose values to fit 2 \n",
    "                                     hour time frame\n",
    "                --> intp_5hrs_dict - dictionaries of consistent length with \n",
    "                                     interpolated glucose values to fit 5 \n",
    "                                     hour time frame\n",
    "        \"\"\"\n",
    "        raw_gluc_dict, intp_2hrs_dict, intp_5hrs_dict = [], [], []\n",
    "\n",
    "        i = 0\n",
    "        windows = self.dex_windows.copy()\n",
    "        for window in windows:\n",
    "            gluc, gluc_2hr, gluc_5hr = {}, {}, {}\n",
    "            \n",
    "            # reads and labels glucose values backwards\n",
    "            glw = window['Glucose Value (mg/dL)'].tolist()[::-1]\n",
    "            glw_2hr = self.interpolate(glw,2)\n",
    "            glw_5hr = self.interpolate(glw,5)\n",
    "\n",
    "            # Current glucose already included from 'get_bmdata' function --> \n",
    "            # idx starts at 1\n",
    "            for i in range(1,len(glw)):\n",
    "                gluc['gluc_'+str(i*5)+'_mins_prior'] = glw[i]\n",
    "            for i in range(1,len(glw_2hr)):\n",
    "                gluc_2hr['gluc_'+str(i*5)+'_mins_prior'] = glw_2hr[i]\n",
    "            for i in range(1,len(glw_5hr)):\n",
    "                gluc_5hr['gluc_'+str(i*5)+'_mins_prior'] = glw_5hr[i]\n",
    "\n",
    "            raw_gluc_dict += [gluc]\n",
    "            intp_2hrs_dict += [gluc_2hr]\n",
    "            intp_5hrs_dict += [gluc_5hr]\n",
    "            \n",
    "        return raw_gluc_dict, intp_2hrs_dict, intp_5hrs_dict\n",
    "\n",
    "    def get_full_dict(self, markers):\n",
    "        \"\"\"\n",
    "        Combines all markers in to one dictionary per window\n",
    "        - input: a list of a list of marker dictionaries\n",
    "        - returns: a list of dictionaries by window\n",
    "        \"\"\"\n",
    "        full_dict = []\n",
    "        for i in range(len(self.meal_dt)):\n",
    "            wndw = {}\n",
    "            for marker in markers:\n",
    "                if not marker[i] is np.nan:\n",
    "                    for key, val in marker[i].items():\n",
    "                        wndw[key] = val\n",
    "                else:\n",
    "                    wndw['NaN'] = np.nan\n",
    "            full_dict += [wndw]\n",
    "        return full_dict\n",
    "    \n",
    "    def add_subject_no(self, full_dict):\n",
    "        \"\"\"\n",
    "        Coverts input dictionary into dataframe and adds Subject number \n",
    "        column dataframe.\n",
    "        - input: dictionary\n",
    "        - returns: pandas dataframe\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame.from_dict(full_dict.copy())\n",
    "        df['subject_no'] = self.n\n",
    "        col = df.columns.tolist()\n",
    "        df = df[[col[-1]] + col[:-1]]\n",
    "        return df\n",
    "        \n",
    "    def assemble(self):\n",
    "        \"\"\"\n",
    "        - Assembles\n",
    "        - Updates the following Class dataframes: raw_gluc_df, intp_2hrs_df,\n",
    "        and intp_5hrs_df\n",
    "        \"\"\"\n",
    "        raw_gluc_dict, intp_2hrs_dict, intp_5hrs_dict = self.get_gluc_dict()\n",
    "        \n",
    "        def get_gluc_df(full_dict, areas):\n",
    "            # support function for Class 'assemble' method\n",
    "            markers = self.markers.copy() + [full_dict, areas]\n",
    "            temp = self.get_full_dict(markers)\n",
    "            df = self.add_subject_no(temp)\n",
    "            \n",
    "            # drop glucose columns with zeros & meal events with glucose zeros\n",
    "            mask = df['ppg_auc']\n",
    "            mask = mask[mask==0].index.tolist()\n",
    "            for i in mask:\n",
    "                df = df.drop(index=i).reset_index(drop=True)\n",
    "\n",
    "            mask = df.columns[df.columns.str.startswith('gluc')].tolist()\n",
    "            for col in mask:\n",
    "                df = [df.drop(columns=col) if df[col].isin([0]).any() else df][0]\n",
    "\n",
    "            return df\n",
    "        \n",
    "        self.raw_gluc_df = get_gluc_df(raw_gluc_dict, self.areas)\n",
    "        self.intp_2hrs_df = get_gluc_df(intp_2hrs_dict, self.intp_2hr_areas)\n",
    "        self.intp_5hrs_df = get_gluc_df(intp_5hrs_dict, self.intp_5hr_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "525f6ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dfs(pn,sub,path=''):\n",
    "    tmp1 = sub.raw_gluc_df.copy()\n",
    "    tmp2 = sub.to_delta(tmp1)\n",
    "    tmp1.to_csv(path+'subject_{n}_raw_gluc_df.csv'.format(n=pn), index=False)\n",
    "    tmp2.to_csv(path+'subject_{n}_raw_gluc_df_delta.csv'.format(n=pn), index=False)\n",
    "    tmp1 = sub.intp_2hrs_df.copy()\n",
    "    tmp2 = sub.to_delta(tmp1)\n",
    "    tmp1.to_csv(path+'subject_{n}_intp_2hrs_df.csv'.format(n=pn), index=False)\n",
    "    tmp2.to_csv(path+'subject_{n}_intp_2hrs_df_delta.csv'.format(n=pn), index=False)\n",
    "    tmp1 = sub.intp_5hrs_df.copy()\n",
    "    tmp2 = sub.to_delta(tmp1)\n",
    "    tmp1.to_csv(path+'subject_{n}_intp_5hrs_df.csv'.format(n=pn), index=False)\n",
    "    tmp2.to_csv(path+'subject_{n}_intp_5hrs_df_delta.csv'.format(n=pn), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6a35f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = [1,2] + list(range(4,17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d62abd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in itr:\n",
    "    sub = CGM_Wide_DF(n=n)\n",
    "    path = 'transformer/wide_df/'\n",
    "    save_dfs(n, sub, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d8919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
